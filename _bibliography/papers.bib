---
---

@arxiv{Azzalini2022,
	title = {Simulating Short-Term Synaptic Plasticity on SpiNNaker Neuromorphic Hardware},
	url = {https://www.biorxiv.org/content/early/2022/09/15/2022.09.13.507796},
	doi = {10.1101/2022.09.13.507796},
	preview = {dbs_effect.png},
	abstract = {Neuromorphic chips are well-suited for the exploration of neuronal dynamics in (near) real-time. In order to port existing research onto these chips, relevant models of neuronal and synaptic dynamics first need to be supported by their respective development environments and validated against existing simulator backends. At the time of writing, support for short-term synaptic plasticity on neuromorphic hardware is scarce. This technical paper proposes an implementation of dynamic synapses for the SpiNNaker development environment based on the popular synaptic plasticity model by Tsodyks and Markram (TM). This extension is undertaken in the context of existing research on neuromodulation and the study of deep brain stimulation (DBS) effects on singular-neuron responses. The implementation of the TM synapse is first detailed and then, simulated for various response types. Its role in studies of DBS effect on postsynaptic responses is also reviewed. Finally, given the real-time capabilities offered by the hardware, we provide some insight to lay the groundwork for future explorations of closed-loop DBS on neuromorphic chips.},
	journal = {bioRxiv},
	author = {Azzalini, Lo誰c J. and Lankarany, Milad},
	year = {2022},
	note = {Publisher: Cold Spring Harbor Laboratory},
    pdf = {https://www.biorxiv.org/content/early/2022/09/15/2022.09.13.507796.full.pdf},
}

@inproceedings{Azzalini2023_2,
  author       = {Azzalini, Lo誰c J. and Izzo, Dario},
  title        = {Tracking Particles Ejected From Active Asteroid Bennu With Event-Based Vision},
  code         = {https://github.com/jazzalin/escape-bennu},
  slides       = {aidaa_2023_azzalini_static.pdf},
  preview      = {bennu_dvs.png},
  abstract     = {Early detection and tracking of ejecta in the vicinity of small solar system bodies is crucial to guarantee spacecraft safety and support scientific observation. During the visit of active asteroid Bennu, the OSIRIS-REx spacecraft relied on the analysis of images captured by onboard navigation cameras to detect particle ejection events, which ultimately became one of the mission's scientific highlights. To increase the scientific return of similar time-constrained missions, this work proposes an event-based solution that is dedicated to the detection and tracking of centimetre-sized particles. Unlike a standard frame-based camera, the pixels of an event-based camera independently trigger events indicating whether the scene brightness has increased or decreased at that time and location in the sensor plane. As a result of the sparse and asynchronous spatiotemporal output, event cameras combine very high dynamic range and temporal resolution with low-power consumption, which could complement existing onboard imaging techniques. This paper motivates the use of a scientific event camera by reconstructing the particle ejection episodes reported by the OSIRIS-REx mission in a photorealistic scene generator and in turn, simulating event-based observations. The resulting streams of spatiotemporal data support future work on event-based multi-object tracking.},
  date         = {2023},
  eventdate    = {2023-09-04/2023-09-07},
  booktitle    = {Proceedings of the XXVII AIDAA International Congress},
  location     = {Padova},
  year = {2023},
  selected = {true},
  doi = {10.21741/9781644902813-124},
  url = {https://doi.org/10.21741/9781644902813-124},
  pdf = {https://doi.org/10.21741/9781644902813-124}
}

@inproceedings{Azzalini2023_3,
  author       = {Azzalini, Lo誰c J. and Blazquez, Emmanuel and Hadjiivanov, Alexander and Meoni, Gabriele and Izzo, Dario},
  title        = {On the Generation of Synthetic Event-Based Vision Datasets for Navigation and Landing},
  code         = {https://gitlab.com/EuropeanSpaceAgency/trajectory-to-events},
  preview      = {landing_motion_field.png},
  slides       = {esa_gnc_2023_azzalini_static.pdf},
  abstract     = {This paper presents a methodology and a software pipeline for generating event-based vision datasets from optimal landing trajectories. The study is motivated by the potential use case for an onboard event-based navigation camera during the approach of a target body and the lack of real-world datasets to support it due to the fact that event-based cameras are relatively new technology. We construct sequences of photorealistic images of the lunar surface with the Planet and Asteroid Natural Scene Generator (PANGU) at various points along optimal descent trajectories with varying boundary conditions. The generated image sequences are then converted into event streams by means of an event-based camera emulator. We demonstrate that the pipeline can generate realistic event-based representations of surface features by constructing a dataset of 500 trajectories, complete with event streams and motion field groundtruth data. We anticipate that novel event-based vision datasets can be generated using this pipeline to support various spacecraft pose reconstruction problems given events as input, and we hope that the proposed methodology would attract the attention of researchers working at the intersection of neuromorphic vision and guidance navigation and control.},
  date         = {2023},
  eventdate    = {2023-06-12/2023-06-16},
  booktitle    = {Proceedings of the 12th International Conference on Guidance, Navigation & Control Systems (GNC)},
  location     = {Sopot},
  year = {2023},
  selected = {true},
  doi = {10.5270/esa-gnc-icatt-2023-202},
  url = {https://doi.org/10.5270/esa-gnc-icatt-2023-202},
  pdf = {https://doi.org/10.5270/esa-gnc-icatt-2023-202}
}

@article{Azzalini2023,
	title = {Adaptive Unscented Kalman Filter for Neuronal State and Parameter Estimation},
	issn = {1573-6873},
	pdf = {https://doi.org/10.1007/s10827-023-00845-z},
	doi = {10.1007/s10827-023-00845-z},
	code = {https://github.com/nsbspl/RAUKF},
	preview = {raukf.png},
	abstract = {Data assimilation techniques for state and parameter estimation are frequently applied in the context of computational neuroscience. In this work, we show how an adaptive variant of the unscented Kalman filter (UKF) performs on the tracking of a conductance-based neuron model. Unlike standard recursive filter implementations, the robust adaptive unscented Kalman filter (RAUKF) jointly estimates the states and parameters of the neuronal model while adjusting noise covariance matrices online based on innovation and residual information. We benchmark the adaptive filter's performance against existing nonlinear Kalman filters and explore the sensitivity of the filter parameters to the system being modelled. To evaluate the robustness of the proposed solution, we simulate practical settings that challenge tracking performance, such as a model mismatch and measurement faults. Compared to standard variants of the Kalman filter the adaptive variant implemented here is more accurate and robust to faults.},
	journal = {Journal of Computational Neuroscience},
	author = {Azzalini, Lo誰c J. and Crompton, David and D'Eleuterio, Gabriele M. T. and Skinner, Frances and Lankarany, Milad},
	month = mar,
	year = {2023},
}