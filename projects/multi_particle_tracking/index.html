<!DOCTYPE html> <html lang=""> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> ESCAPE from Bennu | Loïc J. Azzalini </title> <meta name="author" content="Loïc J. Azzalini"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%AA%90&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="/projects/multi_particle_tracking/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> lja </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Brain Pickings </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">ESCAPE from Bennu</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/bennu_dvs-480.webp 480w,/assets/img/bennu_dvs-800.webp 800w,/assets/img/bennu_dvs-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/bennu_dvs.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bennu_dvs.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Azzalini2023_2" class="col-sm-8"> <div class="title">Tracking Particles Ejected From Active Asteroid Bennu With Event-Based Vision</div> <div class="author"> Loïc J. Azzalini, and Dario Izzo </div> <div class="periodical"> <em>In Proceedings of the XXVII AIDAA International Congress</em> , Padova, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.21741/9781644902813-124" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/jazzalin/escape-bennu" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/aidaa_2023_azzalini_static.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Early detection and tracking of ejecta in the vicinity of small solar system bodies is crucial to guarantee spacecraft safety and support scientific observation. During the visit of active asteroid Bennu, the OSIRIS-REx spacecraft relied on the analysis of images captured by onboard navigation cameras to detect particle ejection events, which ultimately became one of the mission’s scientific highlights. To increase the scientific return of similar time-constrained missions, this work proposes an event-based solution that is dedicated to the detection and tracking of centimetre-sized particles. Unlike a standard frame-based camera, the pixels of an event-based camera independently trigger events indicating whether the scene brightness has increased or decreased at that time and location in the sensor plane. As a result of the sparse and asynchronous spatiotemporal output, event cameras combine very high dynamic range and temporal resolution with low-power consumption, which could complement existing onboard imaging techniques. This paper motivates the use of a scientific event camera by reconstructing the particle ejection episodes reported by the OSIRIS-REx mission in a photorealistic scene generator and in turn, simulating event-based observations. The resulting streams of spatiotemporal data support future work on event-based multi-object tracking.</p> </div> </div> </div> </li></ol> </div> <p>An <em>active</em> asteroid shows evidence of mass loss caused by natural processes, such as water sublimation or the impact of another asteroid, or as a result of human-planned activities (e.g., DART mission). Detecting and interpreting the dynamic properties of these small solar system bodies (SSB) constitute important scientific objectives of sample-return and flyby missions as they may hold the key to understanding their past and future [1]. In the case of asteroid Bennu, such activity was only detected in situ. As visiting spacecraft OSIRIS-REx planned its approach, its navigation cameras picked up on centimetre-size rocks being ejected from the surface, some remaining in Bennu’s orbit, others escaping its gravitational pull entirely. Whether for situational awareness to guarantee spacecraft safety or scientific observation, missions like OSIRIS-REx benefit from early detection and tracking of such events [2]. Following the discovery of particle ejection events, several autonomous detection and tracking approaches have been considered to increase the scientific return of time-constrained missions [3]. Challenges of this approach include the need to detect and match particles from frame to frame under high dynamic range and fast relative dynamics, for which visual identification methods such as <em>blinking</em> images are still often used.</p> <p>Dynamic vision sensing has been shown to be an effective low-power solution to capture data from environments with high dynamic range [4]. These biologically-inspired sensors, commonly known as event-cameras, benefit from independent pixels that asynchronously respond to brightness changes in the scene, departing from the standard frame-based representation of visual intensities. Feature detection and tracking is one area where these novel sensors shine as the absence of frames allows for continuous and asynchronous tracking of multiple objects [5]. The advantages of event-based cameras over standard frame cameras, especially in terms of overall power consumption and dynamic range, has motivated a number of recent studies on their suitability for space applications [6], notably in the area of space situational awareness [7].</p> <p><br></p> <h2>Project goals</h2> <p><br></p> <p>This project aims to further evaluate dynamic vision sensing for future space applications. By reviewing data collected in past missions, we can identify dynamic scenes where an event-based sensor could, in theory, augment visual data capture and contribute to the mission’s scientific objectives. We select the particle ejection episodes observed around active asteroid Bennu to present a use case for event-based multi-object tracking in orbit of a target of scientific interest.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <image class="img-fluid rounded z-depth-1" src="/assets/img/orx_particles_orb_C.png" align="center" alt="" title=""></image> </div> </div> <div class="caption"> Fig. 1: Bennu-fixed particle ejection visualization based on the interpolation of SPICE kernels from 2019-09-13T21:00:00 to 2019-09-14T00:00:00 </div> <p>The first step consists in simulating an event-based representation of an active asteroid from the point of view of a realistic trajectory under lighting conditions that capture the high dynamic range of the deep space environment. Fig. 1 reconstructs from the openly-available SPICE kernels [8] an episode where multiple particles were observed near the surface of Bennu. Particular attention is given to the representation of the centimetre-size particles temporarily orbiting the asteroid, as reported by the OSIRIS-REx mission. The second phase of the project focuses on the development of event-based particle detection and tracking algorithms.</p> <p><br></p> <h2>Simulation</h2> <p><br></p> <p>The particle ejection episodes illustrated in Fig. 1 can be rendered more realistically with computer graphics tools such as Blender. Blender has been used in the past to create textured SSBs, including asteroids resembling the rubble-pile surface of asteroid Bennu [9], to which it is straightforward to add renders of centimetre-size particles. The simulated pinhole camera in Blender is then controlled according to the sampled trajectories depicted in Fig. 1 to generate sequences of frames capturing the active asteroid under realistic lighting conditions. To simulate dynamic vision sensing, the frames are passed through a video-to-event simulator [10], where the sensitivity and the noise of the emulated sensor can be calibrated. Following adequate parameterization of the camera model, particle ejection scenes such as the one depicted on the left in Fig. 2 are reconstructed, from which synthetic event-based representations are then derived (center and right). Given the asynchronous nature of dynamic vision sensing, the illustrations represent accumulations of positive (blue) and negative (red) changes in light brightness into event-frames to allow for a comparison with standard light intensity images.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <image class="img-fluid rounded z-depth-1" src="/assets/img/ejecta_render_3x.png" align="center" alt="" title=""></image> </div> </div> <div class="caption"> Fig. 2: Reconstruction of a particle ejection episode: (a) the particles are difficult to detect in the photorealistic render, (b) yet accumulation of synthetic events in a single frame make the particles more easily identifiable against the dynamic background noise (b) and clearly visible in the absence of noise (c) (the arrows indicate the ejecta direction) </div> <p>The noisy representation of particle ejection episodes (centre image above) will subsequently be used to evaluate event-based multi-object detection and tracking algorithms.</p> <p><br></p> <h2>References</h2> <p><br></p> <p>[1] Lauretta, D. S. et al. (2019). Episodes of particle ejection from the surface of the active asteroid (101955) Bennu. Science, 366 (6470), eaay3544. https://doi.org/10.1126/science.aay3544</p> <p>[2] Chesley, S. R. et al. (2020). Trajectory estimation for particles observed in the vicinity of (101955) Bennu. Journal of Geophysical Research: Planets, 125, e2019JE006363. https://doi.org/10.1029/2019JE006363</p> <p>[3] Liounis, A. J. et al. (2020). Autonomous detection of particles and tracks in optical images. Earth and Space Science, 7, e2019EA000843. https://doi.org/10.1029/2019EA000843</p> <p>[4] Gallego, G. et al. (2022). Event-based vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44 (1), 154-180. https://doi.org/10.1109/TPAMI.2020.3008413</p> <p>[5] Lagorce, X. et al. (2015). Asynchronous Event-Based Multikernel Algorithm for High-Speed Visual Features Tracking. IEEE Transactions on Neural Networks and Learning Systems, vol. 26, no. 8, pp. 1710-1720. https://doi.org/10.1109/TNNLS.2014.2352401</p> <p>[6] Izzo, D. et al. (2022). Neuromorphic computing and sensing in space. arXiv preprint arXiv:2212.05236. https://doi.org/10.48550/arXiv.2212.05236</p> <p>[7] S. Afshar et al. (2020). Event-Based Object Detection and Tracking for Space Situational Awareness. IEEE Sensors Journal, vol. 20, no. 24, pp. 15117-15132. https://doi.org/10.1109/JSEN.2020.3009687</p> <p>[8] Hergenrother, C. W. et al. (2020). Photometry of particles ejected from active asteroid (101955) Bennu. Journal of Geophysical Research: Planets, 125, e2020JE006381. https://doi.org/10.1029/2020JE006381</p> <p>[9] Pajusalu M. et al. (2022) SISPO: Space Imaging Simulator for Proximity Operations. PLOS ONE 17(3): e0263882. https://doi.org/10.1371/journal.pone.0263882</p> <p>[10] Hu, Y. et al. (2021). v2e: From Video Frames to Realistic DVS Events. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Nashville, TN, USA, 2021, pp. 1312-1321, https://doi.org/10.1109/CVPRW53098.2021.00144</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Loïc J. Azzalini. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>